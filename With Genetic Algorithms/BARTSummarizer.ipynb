{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'A New York woman has pleaded not guilty to falsely claiming to be married 10 times, including to eight men from different countries, in what prosecutors say was an immigration scam.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-xsum\")\n",
    "\n",
    "ARTICLE = \"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
    "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
    "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
    "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
    "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
    "2010 marriage license application, according to court documents.\n",
    "Prosecutors said the marriages were part of an immigration scam.\n",
    "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
    "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
    "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
    "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
    "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
    "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
    "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
    "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
    "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
    "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n",
    "\"\"\"\n",
    "print(summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xsum (/dgxa_home/se20ucse203/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12bd518cab74bcaa1514af2d82bf7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 204045\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 11332\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 11334\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed.\n",
      "Repair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water.\n",
      "Trains on the west coast mainline face disruption due to damage at the Lamington Viaduct.\n",
      "Many businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town.\n",
      "First Minister Nicola Sturgeon visited the area to inspect the damage.\n",
      "The waters breached a retaining wall, flooding many commercial properties on Victoria Street - the main shopping thoroughfare.\n",
      "Jeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she could not fault the multi-agency response once the flood hit.\n",
      "However, she said more preventative work could have been carried out to ensure the retaining wall did not fail.\n",
      "\"It is difficult but I do think there is so much publicity for Dumfries and the Nith - and I totally appreciate that - but it is almost like we're neglected or forgotten,\" she said.\n",
      "\"That may not be true but it is perhaps my perspective over the last few days.\n",
      "\"Why were you not ready to help us a bit more when the warning and the alarm alerts had gone out?\"\n",
      "Meanwhile, a flood alert remains in place across the Borders because of the constant rain.\n",
      "Peebles was badly hit by problems, sparking calls to introduce more defences in the area.\n",
      "Scottish Borders Council has put a list on its website of the roads worst affected and drivers have been urged not to ignore closure signs.\n",
      "The Labour Party's deputy Scottish leader Alex Rowley was in Hawick on Monday to see the situation first hand.\n",
      "He said it was important to get the flood protection plan right but backed calls to speed up the process.\n",
      "\"I was quite taken aback by the amount of damage that has been done,\" he said.\n",
      "\"Obviously it is heart-breaking for people who have been forced out of their homes and the impact on businesses.\"\n",
      "He said it was important that \"immediate steps\" were taken to protect the areas most vulnerable and a clear timetable put in place for flood prevention plans.\n",
      "Have you been affected by flooding in Dumfries and Galloway or the Borders? Tell us about your experience of the situation and how it was handled. Email us on selkirk.news@bbc.co.uk or dumfries@bbc.co.uk.\n"
     ]
    }
   ],
   "source": [
    "text = dataset['train']['document'][0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clean-up operations are continuing across the Scottish Borders and Dumfries and Galloway after flooding caused by Storm Frank.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of people affected by flooding in Dumfries and Galloway and the Borders has risen to more than 1,000, the Scottish government has said.\n"
     ]
    }
   ],
   "source": [
    "ARTICLE = dataset['train']['document'][0]\n",
    "summary = list(summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False)[0].values())[0]\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from segtok.segmenter import split_single\n",
    "\n",
    "def NER(summary, text):\n",
    "    tagger = SequenceTagger.load('ner-ontonotes')\n",
    "\n",
    "    sentence = [Sentence(sent, use_tokenizer=True) for sent in split_single(text)]\n",
    "    tagger.predict(sentence)\n",
    "    text_NER = []\n",
    "    for sent in sentence:\n",
    "        for entity in sent.get_spans('ner'):\n",
    "            text_NER.append((entity.text.strip(), entity.tag))\n",
    "\n",
    "    sentence = [Sentence(sent, use_tokenizer=True) for sent in split_single(summary)]\n",
    "    tagger.predict(sentence)\n",
    "    sum_NER = []\n",
    "    for sent in sentence:\n",
    "        for entity in sent.get_spans('ner'):\n",
    "            sum_NER.append((entity.text.strip(), entity.tag))\n",
    "    return sum_NER, text_NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-26 10:06:47,635 SequenceTagger predicts: Dictionary with 75 tags: O, S-PERSON, B-PERSON, E-PERSON, I-PERSON, S-GPE, B-GPE, E-GPE, I-GPE, S-ORG, B-ORG, E-ORG, I-ORG, S-DATE, B-DATE, E-DATE, I-DATE, S-CARDINAL, B-CARDINAL, E-CARDINAL, I-CARDINAL, S-NORP, B-NORP, E-NORP, I-NORP, S-MONEY, B-MONEY, E-MONEY, I-MONEY, S-PERCENT, B-PERCENT, E-PERCENT, I-PERCENT, S-ORDINAL, B-ORDINAL, E-ORDINAL, I-ORDINAL, S-LOC, B-LOC, E-LOC, I-LOC, S-TIME, B-TIME, E-TIME, I-TIME, S-WORK_OF_ART, B-WORK_OF_ART, E-WORK_OF_ART, I-WORK_OF_ART, S-FAC\n",
      "[('Dumfries', 'GPE'), ('Galloway', 'GPE'), ('Borders', 'LOC'), ('more than 1,000', 'CARDINAL'), ('Scottish', 'NORP')]\n",
      "\n",
      "\n",
      "[('Newton Stewart', 'GPE'), ('one', 'CARDINAL'), ('Hawick', 'GPE'), ('Peeblesshire', 'GPE'), ('the Lamington Viaduct', 'FAC'), ('Newton Stewart', 'GPE'), ('the River Cree', 'LOC'), ('First', 'ORDINAL'), ('Nicola Sturgeon', 'PERSON'), ('Victoria Street', 'FAC'), ('Jeanette Tate', 'PERSON'), ('the Cinnamon Cafe', 'ORG'), ('Dumfries', 'GPE'), ('the last few days', 'DATE'), ('Borders', 'LOC'), ('Peebles', 'ORG'), ('Scottish Borders Council', 'ORG'), (\"The Labour Party's\", 'ORG'), ('Scottish', 'NORP'), ('Alex Rowley', 'PERSON'), ('Hawick', 'GPE'), ('Monday', 'DATE'), ('first', 'ORDINAL'), ('Dumfries and Galloway', 'GPE'), ('Borders', 'LOC')]\n"
     ]
    }
   ],
   "source": [
    "sum_NER, text_NER = NER(summary, text)\n",
    "print(sum_NER)\n",
    "print(\"\\n\")\n",
    "print(text_NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204045"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-26 10:07:41,696 SequenceTagger predicts: Dictionary with 75 tags: O, S-PERSON, B-PERSON, E-PERSON, I-PERSON, S-GPE, B-GPE, E-GPE, I-GPE, S-ORG, B-ORG, E-ORG, I-ORG, S-DATE, B-DATE, E-DATE, I-DATE, S-CARDINAL, B-CARDINAL, E-CARDINAL, I-CARDINAL, S-NORP, B-NORP, E-NORP, I-NORP, S-MONEY, B-MONEY, E-MONEY, I-MONEY, S-PERCENT, B-PERCENT, E-PERCENT, I-PERCENT, S-ORDINAL, B-ORDINAL, E-ORDINAL, I-ORDINAL, S-LOC, B-LOC, E-LOC, I-LOC, S-TIME, B-TIME, E-TIME, I-TIME, S-WORK_OF_ART, B-WORK_OF_ART, E-WORK_OF_ART, I-WORK_OF_ART, S-FAC\n",
      "2023-09-26 10:08:03,588 SequenceTagger predicts: Dictionary with 75 tags: O, S-PERSON, B-PERSON, E-PERSON, I-PERSON, S-GPE, B-GPE, E-GPE, I-GPE, S-ORG, B-ORG, E-ORG, I-ORG, S-DATE, B-DATE, E-DATE, I-DATE, S-CARDINAL, B-CARDINAL, E-CARDINAL, I-CARDINAL, S-NORP, B-NORP, E-NORP, I-NORP, S-MONEY, B-MONEY, E-MONEY, I-MONEY, S-PERCENT, B-PERCENT, E-PERCENT, I-PERCENT, S-ORDINAL, B-ORDINAL, E-ORDINAL, I-ORDINAL, S-LOC, B-LOC, E-LOC, I-LOC, S-TIME, B-TIME, E-TIME, I-TIME, S-WORK_OF_ART, B-WORK_OF_ART, E-WORK_OF_ART, I-WORK_OF_ART, S-FAC\n"
     ]
    }
   ],
   "source": [
    "summaries = []\n",
    "train_summaries = []\n",
    "summaries_NER = []\n",
    "train_NER = []\n",
    "for i in range(0,len(dataset['train'])):\n",
    "    ARTICLE = dataset['train']['document'][i]\n",
    "    summary = list(summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False)[0].values())[0]\n",
    "    summaries.append(summary)\n",
    "    train_summaries.append(dataset['train']['summary'][i])\n",
    "    \n",
    "    sum_NER, text_NER = NER(summary, ARTICLE)\n",
    "    summaries_NER.append(sum_NER)\n",
    "    train_NER.append(text_NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {'Original Text': train_summaries, 'NER for Original': train_NER, 'Generated Summaries': summaries, 'NER for Generated': summaries_NER}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Summaries_NER.csv', index = Falses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def frequencies(word, text):\n",
    "    count = 0\n",
    "    word = word.lower()\n",
    "    text = text.lower()\n",
    "    \n",
    "    translator = str.maketrans('', '', string.punctuation+'\\\\')\n",
    "\n",
    "    text = text.translate(translator)\n",
    "    word = word.translate(translator)\n",
    "    n = len(word.split())  # Get the length of the n-gram\n",
    "    if n == 1:\n",
    "        for i in text.split():\n",
    "            if i == word:\n",
    "                count += 1\n",
    "    else:\n",
    "        words = text.split()\n",
    "        for i in range(len(words) - n + 1):\n",
    "            ngram = \" \".join(words[i:i + n])\n",
    "            if ngram == word:\n",
    "                count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "def returnDists(NER_list1, NER_list2, text1, text2):\n",
    "    word_freq1 = []\n",
    "    total_words1 = len(text1.split())\n",
    "    for i in NER_list1:\n",
    "        word_freq1.append((i, float(frequencies(i,text1)/total_words1)))\n",
    "    word_probabilities1 = np.array(word_freq1)\n",
    "    \n",
    "    word_freq2 = []\n",
    "    total_words2 = len(text2.split())\n",
    "    for i in NER_list2:\n",
    "        word_freq2.append((i, float(frequencies(i,text2)/total_words2)))\n",
    "    word_probabilities2 = np.array(word_freq2)\n",
    "\n",
    "    # Display the two probability distributions\n",
    "    print(\"Probability Distribution for Text 1:\")\n",
    "    print(word_probabilities1)\n",
    "\n",
    "    print(\"\\nProbability Distribution for Text 2:\")\n",
    "    print(word_probabilities2)\n",
    "    \n",
    "    return word_probabilities1, word_probabilities2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl(dist1, dist2):\n",
    "    return np.sum(dist1 * np.log(dist1 / dist2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_sum = []\n",
    "for i in sum_NER:\n",
    "    if i[0] not in entities_sum:\n",
    "        entities_sum.append(i[0])\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_text = []\n",
    "for i in text_NER:\n",
    "    if i[0] not in entities_text:\n",
    "        entities_text.append(i[0])\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(entities_sum)):\n",
    "    if i >= len(entities_sum):\n",
    "        break\n",
    "    if entities_sum[i] not in entities_text:\n",
    "        entities_sum.remove(entities_sum[i])\n",
    "        i -= 1\n",
    "\n",
    "for i in range(0,len(entities_text)):\n",
    "    if entities_text[i] not in entities_sum:\n",
    "        entities_sum.append(entities_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Dumfries', 'GPE'), ('Galloway', 'GPE'), ('Borders', 'LOC'), ('more than 1,000', 'CARDINAL'), ('Scottish', 'NORP')] ['Dumfries', 'Borders', 'Scottish', 'Newton Stewart', 'one', 'Hawick', 'Peeblesshire', 'the Lamington Viaduct', 'the River Cree', 'First', 'Nicola Sturgeon', 'Victoria Street', 'Jeanette Tate', 'the Cinnamon Cafe', 'the last few days', 'Peebles', 'Scottish Borders Council', \"The Labour Party's\", 'Alex Rowley', 'Monday', 'first', 'Dumfries and Galloway']\n",
      "[('Newton Stewart', 'GPE'), ('one', 'CARDINAL'), ('Hawick', 'GPE'), ('Peeblesshire', 'GPE'), ('the Lamington Viaduct', 'FAC'), ('Newton Stewart', 'GPE'), ('the River Cree', 'LOC'), ('First', 'ORDINAL'), ('Nicola Sturgeon', 'PERSON'), ('Victoria Street', 'FAC'), ('Jeanette Tate', 'PERSON'), ('the Cinnamon Cafe', 'ORG'), ('Dumfries', 'GPE'), ('the last few days', 'DATE'), ('Borders', 'LOC'), ('Peebles', 'ORG'), ('Scottish Borders Council', 'ORG'), (\"The Labour Party's\", 'ORG'), ('Scottish', 'NORP'), ('Alex Rowley', 'PERSON'), ('Hawick', 'GPE'), ('Monday', 'DATE'), ('first', 'ORDINAL'), ('Dumfries and Galloway', 'GPE'), ('Borders', 'LOC')] ['Newton Stewart', 'one', 'Hawick', 'Peeblesshire', 'the Lamington Viaduct', 'the River Cree', 'First', 'Nicola Sturgeon', 'Victoria Street', 'Jeanette Tate', 'the Cinnamon Cafe', 'Dumfries', 'the last few days', 'Borders', 'Peebles', 'Scottish Borders Council', \"The Labour Party's\", 'Scottish', 'Alex Rowley', 'Monday', 'first', 'Dumfries and Galloway']\n"
     ]
    }
   ],
   "source": [
    "print(sum_NER, entities_sum)\n",
    "print(text_NER, entities_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed.\n",
      "Repair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water.\n",
      "Trains on the west coast mainline face disruption due to damage at the Lamington Viaduct.\n",
      "Many businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town.\n",
      "First Minister Nicola Sturgeon visited the area to inspect the damage.\n",
      "The waters breached a retaining wall, flooding many commercial properties on Victoria Street - the main shopping thoroughfare.\n",
      "Jeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she could not fault the multi-agency response once the flood hit.\n",
      "However, she said more preventative work could have been carried out to ensure the retaining wall did not fail.\n",
      "\"It is difficult but I do think there is so much publicity for Dumfries and the Nith - and I totally appreciate that - but it is almost like we're neglected or forgotten,\" she said.\n",
      "\"That may not be true but it is perhaps my perspective over the last few days.\n",
      "\"Why were you not ready to help us a bit more when the warning and the alarm alerts had gone out?\"\n",
      "Meanwhile, a flood alert remains in place across the Borders because of the constant rain.\n",
      "Peebles was badly hit by problems, sparking calls to introduce more defences in the area.\n",
      "Scottish Borders Council has put a list on its website of the roads worst affected and drivers have been urged not to ignore closure signs.\n",
      "The Labour Party's deputy Scottish leader Alex Rowley was in Hawick on Monday to see the situation first hand.\n",
      "He said it was important to get the flood protection plan right but backed calls to speed up the process.\n",
      "\"I was quite taken aback by the amount of damage that has been done,\" he said.\n",
      "\"Obviously it is heart-breaking for people who have been forced out of their homes and the impact on businesses.\"\n",
      "He said it was important that \"immediate steps\" were taken to protect the areas most vulnerable and a clear timetable put in place for flood prevention plans.\n",
      "Have you been affected by flooding in Dumfries and Galloway or the Borders? Tell us about your experience of the situation and how it was handled. Email us on selkirk.news@bbc.co.uk or dumfries@bbc.co.uk.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability Distribution for Text 1:\n",
      "[['Dumfries' '0.04']\n",
      " ['Borders' '0.04']\n",
      " ['Scottish' '0.04']\n",
      " ['Newton Stewart' '0.0']\n",
      " ['one' '0.0']\n",
      " ['Hawick' '0.0']\n",
      " ['Peeblesshire' '0.0']\n",
      " ['the Lamington Viaduct' '0.0']\n",
      " ['the River Cree' '0.0']\n",
      " ['First' '0.0']\n",
      " ['Nicola Sturgeon' '0.0']\n",
      " ['Victoria Street' '0.0']\n",
      " ['Jeanette Tate' '0.0']\n",
      " ['the Cinnamon Cafe' '0.0']\n",
      " ['the last few days' '0.0']\n",
      " ['Peebles' '0.0']\n",
      " ['Scottish Borders Council' '0.0']\n",
      " [\"The Labour Party's\" '0.0']\n",
      " ['Alex Rowley' '0.0']\n",
      " ['Monday' '0.0']\n",
      " ['first' '0.0']\n",
      " ['Dumfries and Galloway' '0.04']]\n",
      "\n",
      "Probability Distribution for Text 2:\n",
      "[['Newton Stewart' '0.005']\n",
      " ['one' '0.0025']\n",
      " ['Hawick' '0.005']\n",
      " ['Peeblesshire' '0.0025']\n",
      " ['the Lamington Viaduct' '0.0025']\n",
      " ['the River Cree' '0.0025']\n",
      " ['First' '0.005']\n",
      " ['Nicola Sturgeon' '0.0025']\n",
      " ['Victoria Street' '0.0025']\n",
      " ['Jeanette Tate' '0.0025']\n",
      " ['the Cinnamon Cafe' '0.0025']\n",
      " ['Dumfries' '0.005']\n",
      " ['the last few days' '0.0025']\n",
      " ['Borders' '0.0075']\n",
      " ['Peebles' '0.0025']\n",
      " ['Scottish Borders Council' '0.0025']\n",
      " [\"The Labour Party's\" '0.0025']\n",
      " ['Scottish' '0.005']\n",
      " ['Alex Rowley' '0.0025']\n",
      " ['Monday' '0.0025']\n",
      " ['first' '0.005']\n",
      " ['Dumfries and Galloway' '0.0025']]\n"
     ]
    }
   ],
   "source": [
    "d1, d2 = returnDists(entities_sum, entities_text, summary, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist1 = []\n",
    "for i in range(0,len(d1)):\n",
    "    temp = float(d1[i][1])\n",
    "    dist1.append([d1[i][0], temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist2 = []\n",
    "for i in range(0,len(d2)):\n",
    "    temp = float(d2[i][1])\n",
    "    dist2.append([d2[i][0], temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['Dumfries', 0.04],\n",
       "  ['Borders', 0.04],\n",
       "  ['Scottish', 0.04],\n",
       "  ['Newton Stewart', 0.0],\n",
       "  ['one', 0.0],\n",
       "  ['Hawick', 0.0],\n",
       "  ['Peeblesshire', 0.0],\n",
       "  ['the Lamington Viaduct', 0.0],\n",
       "  ['the River Cree', 0.0],\n",
       "  ['First', 0.0],\n",
       "  ['Nicola Sturgeon', 0.0],\n",
       "  ['Victoria Street', 0.0],\n",
       "  ['Jeanette Tate', 0.0],\n",
       "  ['the Cinnamon Cafe', 0.0],\n",
       "  ['the last few days', 0.0],\n",
       "  ['Peebles', 0.0],\n",
       "  ['Scottish Borders Council', 0.0],\n",
       "  [\"The Labour Party's\", 0.0],\n",
       "  ['Alex Rowley', 0.0],\n",
       "  ['Monday', 0.0],\n",
       "  ['first', 0.0],\n",
       "  ['Dumfries and Galloway', 0.04]],\n",
       " [['Newton Stewart', 0.005],\n",
       "  ['one', 0.0025],\n",
       "  ['Hawick', 0.005],\n",
       "  ['Peeblesshire', 0.0025],\n",
       "  ['the Lamington Viaduct', 0.0025],\n",
       "  ['the River Cree', 0.0025],\n",
       "  ['First', 0.005],\n",
       "  ['Nicola Sturgeon', 0.0025],\n",
       "  ['Victoria Street', 0.0025],\n",
       "  ['Jeanette Tate', 0.0025],\n",
       "  ['the Cinnamon Cafe', 0.0025],\n",
       "  ['Dumfries', 0.005],\n",
       "  ['the last few days', 0.0025],\n",
       "  ['Borders', 0.0075],\n",
       "  ['Peebles', 0.0025],\n",
       "  ['Scottish Borders Council', 0.0025],\n",
       "  [\"The Labour Party's\", 0.0025],\n",
       "  ['Scottish', 0.005],\n",
       "  ['Alex Rowley', 0.0025],\n",
       "  ['Monday', 0.0025],\n",
       "  ['first', 0.005],\n",
       "  ['Dumfries and Galloway', 0.0025]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist1, dist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort both distributions based on the words (first element of each tuple)\n",
    "dist1 = sorted(dist1, key=lambda x: x[0])\n",
    "dist2 = sorted(dist2, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(dist2)):\n",
    "    if i>=len(dist2):\n",
    "        break\n",
    "    if dist2[i][1] == 0.0:\n",
    "        dist1 = np.delete(dist1,i, axis = 0)\n",
    "        dist2 = np.delete(dist2,i, axis = 0)\n",
    "        i -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist1_keys = dist1\n",
    "dist2_keys = dist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(dist1)):\n",
    "    dist1[i] = dist1[i][1]\n",
    "for i in range(0,len(dist2)):\n",
    "    dist2[i] = dist2[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34421792956684494"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import rel_entr\n",
    "\n",
    "sum(rel_entr(dist1, dist2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array(['Alex Rowley', '0.0'], dtype='<U32'),\n",
       "  array(['Borders', '0.04'], dtype='<U32'),\n",
       "  array(['Dumfries', '0.04'], dtype='<U32'),\n",
       "  array(['Dumfries and Galloway', '0.0'], dtype='<U32'),\n",
       "  array(['First', '0.0'], dtype='<U32'),\n",
       "  array(['Hawick', '0.0'], dtype='<U32'),\n",
       "  array(['Jeanette Tate', '0.0'], dtype='<U32'),\n",
       "  array(['Monday', '0.0'], dtype='<U32'),\n",
       "  array(['Newton Stewart', '0.0'], dtype='<U32'),\n",
       "  array(['Nicola Sturgeon', '0.0'], dtype='<U32'),\n",
       "  array(['Peebles', '0.0'], dtype='<U32'),\n",
       "  array(['Peeblesshire', '0.0'], dtype='<U32'),\n",
       "  array(['Scottish', '0.04'], dtype='<U32'),\n",
       "  array(['Scottish Borders Council', '0.0'], dtype='<U32'),\n",
       "  array([\"The Labour Party's\", '0.0'], dtype='<U32'),\n",
       "  array(['Victoria Street', '0.0'], dtype='<U32'),\n",
       "  array(['first', '0.0'], dtype='<U32'),\n",
       "  array(['one', '0.0'], dtype='<U32'),\n",
       "  array(['the Cinnamon Cafe', '0.0'], dtype='<U32'),\n",
       "  array(['the Lamington Viaduct', '0.0'], dtype='<U32'),\n",
       "  array(['the River Cree', '0.0'], dtype='<U32'),\n",
       "  array(['the last few days', '0.0'], dtype='<U32')],\n",
       " [array(['Alex Rowley', '0.0'], dtype='<U32'),\n",
       "  array(['Borders', '0.005'], dtype='<U32'),\n",
       "  array(['Dumfries', '0.005'], dtype='<U32'),\n",
       "  array(['Dumfries and Galloway', '0.0'], dtype='<U32'),\n",
       "  array(['First', '0.0025'], dtype='<U32'),\n",
       "  array(['Hawick', '0.005'], dtype='<U32'),\n",
       "  array(['Jeanette Tate', '0.0'], dtype='<U32'),\n",
       "  array(['Monday', '0.0025'], dtype='<U32'),\n",
       "  array(['Newton Stewart', '0.0'], dtype='<U32'),\n",
       "  array(['Nicola Sturgeon', '0.0'], dtype='<U32'),\n",
       "  array(['Peebles', '0.0025'], dtype='<U32'),\n",
       "  array(['Peeblesshire', '0.0025'], dtype='<U32'),\n",
       "  array(['Scottish', '0.005'], dtype='<U32'),\n",
       "  array(['Scottish Borders Council', '0.0'], dtype='<U32'),\n",
       "  array([\"The Labour Party's\", '0.0'], dtype='<U32'),\n",
       "  array(['Victoria Street', '0.0'], dtype='<U32'),\n",
       "  array(['first', '0.0025'], dtype='<U32'),\n",
       "  array(['one', '0.0025'], dtype='<U32'),\n",
       "  array(['the Cinnamon Cafe', '0.0'], dtype='<U32'),\n",
       "  array(['the Lamington Viaduct', '0.0'], dtype='<U32'),\n",
       "  array(['the River Cree', '0.0'], dtype='<U32'),\n",
       "  array(['the last few days', '0.0'], dtype='<U32')])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1, d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"original = []\n",
    "summaries = []\n",
    "ner_original = []\n",
    "ner_summary = []\n",
    "for i in range(0,len(dataset['train'])):\n",
    "    print(i)\n",
    "    original.append(dataset['train']['document'][i])\n",
    "    ARTICLE = dataset['train']['document'][i]\n",
    "    summary = list(summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False)[0].values())[0]\n",
    "    summaries.append(summary)\n",
    "    print(\"Summaries done\")\n",
    "    sum_NER, text_NER = NER(summary)\n",
    "    ner_original.append(text_NER)\n",
    "    ner_summary.append(sum_NER)\n",
    "    print(\"NER done\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sumenv",
   "language": "python",
   "name": "sumenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
